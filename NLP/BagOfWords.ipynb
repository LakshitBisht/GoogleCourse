{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bag of words is a natural language processing technique of text modelling.',\n",
       " 'in technical terms, we can say that it is a method of feature extraction with text data.',\n",
       " 'this approach is a simple and flexible way of extracting features from documents.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "text = \"Bag of words is a Natural Language Processing technique of text modelling. In technical terms, we can say that it is a method of feature extraction with text data. This approach is a simple and flexible way of extracting features from documents.\"\n",
    "dataset = nltk.sent_tokenize(text)\n",
    "for i in range(len(dataset)):\n",
    "\tdataset[i] = dataset[i].lower()\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bag': 1,\n",
       " 'of': 4,\n",
       " 'words': 1,\n",
       " 'is': 3,\n",
       " 'a': 3,\n",
       " 'natural': 1,\n",
       " 'language': 1,\n",
       " 'processing': 1,\n",
       " 'technique': 1,\n",
       " 'text': 2,\n",
       " 'modelling': 1,\n",
       " '.': 3,\n",
       " 'in': 1,\n",
       " 'technical': 1,\n",
       " 'terms': 1,\n",
       " ',': 1,\n",
       " 'we': 1,\n",
       " 'can': 1,\n",
       " 'say': 1,\n",
       " 'that': 1,\n",
       " 'it': 1,\n",
       " 'method': 1,\n",
       " 'feature': 1,\n",
       " 'extraction': 1,\n",
       " 'with': 1,\n",
       " 'data': 1,\n",
       " 'this': 1,\n",
       " 'approach': 1,\n",
       " 'simple': 1,\n",
       " 'and': 1,\n",
       " 'flexible': 1,\n",
       " 'way': 1,\n",
       " 'extracting': 1,\n",
       " 'features': 1,\n",
       " 'from': 1,\n",
       " 'documents': 1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCount = {}\n",
    "for data in dataset:\n",
    "\twords = nltk.word_tokenize(data)\n",
    "\tfor word in words:\n",
    "\t\tif word not in wordCount.keys():\n",
    "\t\t\twordCount[word] = 1\n",
    "\t\telse:\n",
    "\t\t\twordCount[word] += 1\n",
    "wordCount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['of', 'is', 'a', '.', 'text', 'bag', 'words', 'natural', 'language', 'processing', 'technique', 'modelling', 'in', 'technical', 'terms', ',', 'we', 'can', 'say', 'that', 'it', 'method', 'feature', 'extraction', 'with', 'data', 'this', 'approach', 'simple', 'and', 'flexible', 'way', 'extracting', 'features', 'from', 'documents']\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "freq_words = heapq.nlargest(100, wordCount, key=wordCount.get)\n",
    "print(freq_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "for data in dataset:\n",
    "\tvector = []\n",
    "\tfor word in nltk.word_tokenize(data):\n",
    "\t\tif word in freq_words:\n",
    "\t\t\tvector.append(1)\n",
    "\t\telse:\n",
    "\t\t\tvector.append(0)\n",
    "\tX.append(vector)\n",
    "X = np.asarray(X)\n",
    "\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a99ddddd9707e996f158d5f15667ccf85de0da941d875ebc755d121abccb487d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
